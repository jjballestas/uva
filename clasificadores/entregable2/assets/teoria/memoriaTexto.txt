TÉCNICAS ESCALABLES DE ANÁLISIS DE DATOS EN
ENTORNOS BIG DATA: CLASIFICADORES
Escuela de Ingeniería Informática
2025 - 2026
Proyecto de clasificación
Census Income KDD
Rocha, Nataly
Avendaño, Romell E.
Iribarren, OscarTabla de Contenido
Introducción ................................................................................................................... 4
1. Resumen ejecutivo del conjunto de datos .................................................................. 5
1.1 Origen de los datos. .............................................................................................. 5
1.2 Propósito y uso de los datos. ................................................................................ 5
1.3 Tamaño del conjunto de datos.............................................................................. 5
1.4 Número total y tipo de atributos........................................................................... 5
1.5 Descripción de la Clase. ....................................................................................... 6
2. Exploración de datos .................................................................................................. 7
2.1 Descripción del problema. ................................................................................... 7
2.1.1. Interés del problema ..................................................................................... 7
2.1.2 Análisis socioeconómico ............................................................................... 7
2.1.3 Políticas públicas ........................................................................................... 8
2.1.4 Empresas y negocios ..................................................................................... 8
2.1.5. Complejidades del problema ........................................................................ 8
2.2 Descripción del conjunto de datos. ...................................................................... 9
2.2.1 Descripción de atributos. ............................................................................. 10
2.2.2 Atributo de Clase. ....................................................................................... 41
2.2.3 Valores fuera de rango. ............................................................................... 42
2.2.4 Atributos con valores nulos o faltantes. ...................................................... 42
2.2.5 Outliers. ....................................................................................................... 43
2.2.6 Atributos protegidos. ................................................................................... 43
2.3 Análisis de correlación de los datos. .................................................................. 45
2.3.1 Correlación con PTOTVAL ........................................................................ 45
2.3.2 Códigos de Industria. .................................................................................. 46
2.3.3 Detalle de vivienda. ..................................................................................... 47
2.3.4 Lugares de residencia. ................................................................................. 48
2.3.5 Variables con baja relevancia y posibles opciones. .................................... 48
2.3.6 Correlación de las variables numéricas. ...................................................... 52
22.4 Conclusiones del análisis de datos. ................................................................ 53
3. Preparación de datos ................................................................................................ 55
3.1 Creación de conjuntos de entrenamiento y prueba............................................. 55
3.2 Limpieza de datos. ............................................................................................. 55
3.3 Selección de atributos. ....................................................................................... 57
3.4 Transformación de datos. ................................................................................... 58
4. Conclusiones ............................................................................................................ 61
5. Participación ............................................................................................................. 62
6. Referencias Bibliográficas ....................................................................................... 63
3Introducción
El presente proyecto tiene como propósito desarrollar un modelo de clasificación
empleando técnicas de aprendizaje automático aplicadas a entornos Big data, con el fin de
analizar y predecir patrones socioeconómicos a partir de información censal. El trabajo aborda
las principales fases del ciclo de vida de un proyecto de ciencia de datos.
En concreto, se trabajará con el conjunto de datos Census Income (KDD), disponible
en
la
plataforma
UCI
Machine
Learning
Repository
https://archive.ics.uci.edu/dataset/117/census+income+kdd.
Este dataset contiene información proveniente de las encuestas de población actual
realizadas por la oficina del censo de Estados Unidos en los años 1994 y 1995, e incluye
atributos demográficos, educativos, laborales y económicos.
El proyecto contempla las siguientes etapas:
•Resumen ejecutivo del conjunto de datos
•Exploración de datos
•Preparación de datos
Durante su desarrollo se abordarán diversos desafíos asociados al tratamiento de datos
reales, tales como la presencia de valores fuera de rango, ruido e inconsistencias en la
documentación del dataset.
41. Resumen ejecutivo del conjunto de datos
El conjunto de datos Census Income (KDD) contiene información censal ponderada
obtenida de las Encuestas de Población Actual (Current Population Survey) de los años 1994
y 1995, realizadas por la Oficina de Censo de los Estados Unidos.
El dataset está compuesto por 299.285 registros y 41 tributos tanto categóricos como
numéricos, que incluyen variables como la edad, el sexo, nivel educativo, ocupación, estado
civil, tamaño del empleador, número de horas trabajadas por semana y nacionalidad, entre
otras.
Este conjunto de datos es ampliamente utilizado en la investigación y docencia en
aprendizaje automático y minería de datos, ya que permite evaluar y comparar el desempeño
de distintos algoritmos de clasificación binaria, tales como la regresión logística, los árboles de
decisión, los bosques aleatorios y las redes neuronales.
1.1 Origen de los datos.
UCI Machine Learning Repository – Census Income (KDD) Data Set
https://archive.ics.uci.edu/dataset/117/census+income+kdd
1.2 Propósito y uso de los datos.
El objetivo principal de este conjunto de datos es predecir si el ingreso anual de una
persona supera los 50.000 dólares, a partir del análisis de variables demográficas, educativas,
familiares y laborales.
El problema se formula como una clasificación binaria, donde la variable objetivo
refleja el nivel de ingresos de cada individuo.
1.3 Tamaño del conjunto de datos.
El dataset se divide en dos subconjuntos.
Data (entrenamiento): 199.523 instancias y Test (prueba): 99.762 instancias.
En total, cuenta con 299.285 registros, cada uno correspondiente a una persona.
1.4 Número total y tipo de atributos.
El conjunto incluye 41 atributos, aunque uno de ellos (“instance weight”) se utiliza
únicamente como peso de muestra y debe ser ignorado para el entrenamiento de clasificadores.
Por tanto, el análisis se realiza sobre 40 atributos distribuidos en: 6 atributos continuos
(numéricos) y 34 atributos nominales (categóricos)
5Las variables describen características como edad, nivel educativo, ocupación, estado
civil, relación familiar, nacionalidad, horas trabajadas por semana, entre otras.
1.5 Descripción de la Clase.
La clase, denominada “PTOTVAL” (total person income), representa el rango de
ingresos totales de cada individuo.
Es una variable binaria con las siguientes categorías:
“-50000”: ingresos menores o iguales a 50.000 USD (93,8% de los casos)
“+50000”: ingresos superiores a 50.000 USD (6,2% de los casos)
Esta distribución altamente desbalanceada plantea un desafío adicional para los
modelos de clasificación, que deberán ser evaluados teniendo en cuenta este desequilibrio de
clases.
62. Exploración de datos
2.1 Descripción del problema.
En este estudio se utiliza un conjunto de datos proveniente de la Oficina del Censo de
los Estados Unidos correspondiente a los años 1994 y 1995, con el objetivo de construir un
modelo de machine learning de clasificación binaria capaz de predecir si una persona tiene un
ingreso anual superior o inferior a 50.000 USD.
La tarea de predicción consiste en determinar el nivel de ingreso de cada individuo a
partir de sus características demográficas y laborales. Los ingresos han sido discretizados en
torno a los 50.000 USD, lo que plantea un problema de clasificación binaria similar a la base
de datos de UCI/ADULT. Sin embargo, el campo objetivo utilizado en este caso proviene de
la variable “total person income”, en lugar del “adjusted gross income” empleado en el
conjunto original, lo que puede generar diferencias en el comportamiento del modelo.
2.1.1. Interés del problema
La clasificación de individuos según su nivel de ingresos constituye un aspecto
fundamental en diversos ámbitos, tanto desde la perspectiva económica como desde la social
Este tipo de modelos tiene múltiples aplicaciones, entre las que destacan:
2.1.2 Análisis socioeconómico
El uso de clasificadores en el análisis socioeconómico permite explorar la relación entre
variables demográficas, educativas, laborales y geográficas con los niveles de ingresos de la
población. Este tipo de modelización ofrece una herramienta potente para economistas,
sociólogos y responsables de políticas públicas, ya que posibilita identificar patrones
estructurales de desigualdad y estimar la probabilidad de pertenecer a determinados grupos
socioeconómicos.
A nivel internacional, organismos como el Banco Mundial o la OCDE emplean
metodologías estandarizadas para medir pobreza e inequidad, basadas en umbrales de ingreso
ajustados por la paridad del poder adquisitivo (PPA). Las transformaciones económicas y
sociales de las últimas décadas han impulsado la actualización constante de estos umbrales y
de las metodologías de medición, incorporando además análisis de datos masivos (Big Data) y
técnicas de machine learning para mejorar la comprensión de la dinámica de los ingresos y la
pobreza.
72.1.3 Políticas públicas
El uso de modelos de clasificación en el ámbito de las políticas públicas permite a los
gobiernos identificar grupos poblacionales en situación de vulnerabilidad y dirigir de manera
más eficiente los recursos y programas sociales. A través del análisis de variables como ingreso,
nivel educativo, ocupación o características demográficas, es posible construir perfiles
socioeconómicos que ayuden a detectar desigualdades estructurales y orientar la formulación
de políticas de inclusión.
El Programa de las Naciones Unidas para el Desarrollo (PNUD) promueven el uso de
herramientas analíticas y modelos predictivos para mejorar la focalización de las políticas
públicas. En este contexto, las técnicas de machine learning y clasificación supervisada ofrecen
ventajas significativas, ya que permiten:
•Detectar patrones de vulnerabilidad no evidentes a simple vista.
•Anticipar el riesgo de exclusión o pobreza en determinados segmentos.
•Optimizar la asignación de recursos públicos.
2.1.4 Empresas y negocios
En el ámbito empresarial, la aplicación de modelos de clasificación resulta fundamental
para segmentar a los clientes según su nivel de ingresos y comportamiento de consumo, lo que
permite diseñar estrategias de marketing más efectivas y personalizadas. A partir del análisis
de datos demográficos, transaccionales y digitales, las empresas pueden identificar patrones
que reflejan las preferencias y necesidades de diferentes grupos socioeconómicos, optimizando
así la oferta de productos y servicios.
El uso de algoritmos de machine learning como árboles de decisión, regresión logística
o clustering supervisado permite clasificar a los consumidores en segmentos con alta precisión,
facilitando la personalización del mensaje publicitario, la fijación dinámica de precios y la
recomendación de productos en tiempo real. Esta práctica, conocida como marketing basado
en datos (data-driven marketing), impulsa la competitividad al mejorar la eficiencia de las
campañas y la retención de clientes.
2.1.5. Complejidades del problema
El problema presenta varios retos entre los que podemos destacar:
2.1.5.1 Ruido de datos y valores faltantes.
Una de las principales complejidades encontradas en el conjunto de datos Census-
Income (KDD) es la presencia de ruido e información incompleta. Este tipo de problema es
común en bases de datos socioeconómicas de gran escala, donde los datos provienen de
8múltiples fuentes y pueden contener errores de registro, inconsistencias o valores fuera de rango
en distintos atributos.
Para mitigar estos problemas, se realizó un proceso de limpieza de datos que incluyó la
detección y tratamiento de valores no válidos mediante eliminación controlada de registros,
según el caso, así como la identificación y manejo de outliers o registros inconsistentes. Estas
acciones permitieron reducir el impacto del ruido y mejorar la calidad de la información
disponible
2.1.5.2 Inconsistencias entre los atributos y el conjunto de datos
Durante la etapa de exploración y comprensión del conjunto de datos Census-Income
(KDD), se detectaron inconsistencias entre la descripción oficial de los atributos y el contenido
real del dataset. En particular, se observó que la documentación disponible no correspondía de
manera exacta con el orden o la denominación de los campos presentes en el archivo de datos,
lo que dificultó inicialmente la correcta interpretación de algunas variables.
Además, varios nombres de atributos resultaban poco claros o no explicativos, lo que
exigió un proceso adicional de verificación y correspondencia entre las variables descritas en
la fuente original y las columnas efectivamente presentes en el conjunto de datos. Este proceso
implicó identificar posibles desalineaciones en el orden de las columnas y validar el significado
de cada atributo durante al análisis.
2.2 Descripción del conjunto de datos.
Se presentan los datos en dos archivos por separado el primero de datos census-
income.data con 199 523 instancias y el archivo de pruebas census-income.test con 99 762
instancias. Los cuales incluyen una instancia por línea con campos delimitados por comas.
Los datos contienen 41 variables demográficas y relacionadas con el empleo. De los
cuales la variable instance weight no debe ser tomada para clasificadores y no será tomada en
cuenta dejándonos con 40 variables.
Acorde a la fuente del dataset, los datos se dividieron en entrenamiento/prueba en
proporciones aproximadas de 2/3 y 1/3 utilizando MIndUtil mineset-to-mlc de MineSet.
Realizando la exploración de datos en el conjunto de entrenamiento se ha identificado
las siguientes características:
92.2.1 Descripción de atributos.
El conjunto de datos cuenta con 41 atributos incluyendo el atributo que se considera
como el atributo de clase.
2.2.1.1 Variables Numéricas
2.2.1.1.1 AAGE
AAGE
Edad de la persona a la que se le realizó la encuesta (age)
TipoTotalMediaDesviación
estándarMínimoMáximoTotal Nulos
Numérico
Continuo199.52334,4922,310900
Distribución
Dispersion
10Outliers
No se detectan outliers
2.2.1.1.2 AHRSPAY
AHRSPAY
Salario por hora
TipoTotalMediaDesviación
estándarMínimoMáximoTotal Nulos
Numéric
o
Continu
o199.52355,43274,9099990
Distribució
n
11Dispersion
Outliers
El atributo presenta una distribución altamente concentrada en el valor 0,
con muy poca dispersión. Tanto el método IQR como el Z-score robusto
confirman la ausencia de valores atípicos significativos.
Desde la perspectiva del modelado, esta baja varianza indica que el
atributo aporta escasa información discriminativa para la clasificación. Por
tanto, su inclusión podría introducir ruido o redundancia sin mejorar el
desempeño del modelo. Se considera candidato a ser eliminado o
transformado (por ejemplo, binarizando su presencia o ausencia de valor
distinto de cero).
2.2.1.1.3 CAPGAIN
CAPGAIN
12Ganancias por ingresos de capital.
TipoTotalMediaDesviación
estándarMínimoMáximoTotal Nulo
Numéric
o
Continu
o199.523434,724.697,53099990
Distribució
n
Dispersion
13Outliers
Tenemos el mismo caso que AHRSPAY en este valor. Los valores no son
suficientemente extremos y casi no hay valores mayores a 0, lo cual no
permite detectar outliers.
2.2.1.1.4 CAPLOSS
CAPLOSS
Pérdidas de capital que ha sufrido la personal (Capital Loss)
TipoTotalMediaDesviación
estándarMínimoMáximoTotal Nulo
Numéric
o
Continu
o199.52337,31271,904.6080
Distribució
n
14Dispersion
Outliers
Tenemos el mismo caso que AHRSPAY en este valor. Los valores no son
suficientemente extremos y casi no hay valores mayores a 0, lo cual no
permite detectar outliers.
2.2.1.1.5 DIVVAL
DIVVAL
Dividendos recibidos de las acciones (Dividens from Stocks)
TipoTotalMediaDesviación
estándarMínimoMáximoTotal Nulo
Numéric
o
Continu
o199.523197.531.984,16099.9990
15Distribució
n
Dispersión
Outliers
Tenemos el mismo caso que AHRSPAY en este valor. Los valores no son
suficientemente extremos y casi no hay valores mayores a 0, lo cual no
permite detectar outliers.
162.2.1.1.6 WKSWORK
WKSWORK
Número de Semanas trabajadas por la persona en el año (Weeks worked in Year)
TipoTotalMediaDesviación
estándarMínimoMáximoTotal Nulo
Numéric
o
Discreto199.52323,1724,110520
Distribució
n
Outliers
Aunque no hay outliers, esta distribución de igual manera nos hace pensar
que se podría simplificar mucho los valores de WKSWORK para el
17modelo. Debido a que solo tiene dos valores significativos en su
distribución.
2.2.1.2 Variables Categóricas
2.2.1.2.1 NOEMP
NOEMP
Número de personas que trabajan para el empleador.
Tipo: Categórico
Valores posibles: 0,1,2,3,4,5,6
Valores ausentes: 0
Moda: 24.11
Distribución
(frecuencia)
2.2.1.2.2 ACLSWKR
ACLSWKR
Clase de trabajador
Tipo: Categorico
Moda: Not in universe
Valores faltantes: 0
Posibles valores: Never worked, State government, Local government, Private, Self-employed-
incorporated, Not in universe, Self-employed-not incorporated, Federal government, Without pay
18Di
str
ib
uc
ió
n
2.2.1.2.3 ADTINK
ADTINK
Código de Industria
Tipo: Categorico
Moda: 0
Valores faltantes: 0
Posibles valores: 51, 26, 28, 6, 23, 12, 11, 3, 16, 4, 7, 14, 44, 9, 48, 43, 36, 29, 46, 15, 22,
32, 49, 10, 33, 45, 41, 35, 40, 24, 42, 18, 21, 1, 19, 0, 34, 31, 25, 50, 27, 5, 39, 30, 38, 8,
17, 47, 13, 20, 37, 2
Distribución
19Dependiendo su relevancia posible candidata para simplificar
binarizando.
2.2.1.2.4 ADTOCC
ADTOCC
Código de Ocupación
Tipo: Categorico
Moda: 0
Valores faltantes: 0
Posibles valores: 26, 28, 6, 23, 12, 11, 3, 16, 4, 7, 14, 44, 9, 43, 36, 29, 46, 15, 22, 32, 10,
33, 45, 41, 35, 40, 24, 42, 18, 21, 1, 19, 0, 34, 31, 25, 27, 5, 39, 30, 38, 8, 17, 13, 20, 37,
2
Distribución
2.2.1.2.5 AHGA
AHGA
Nivel de educación de la persona.
Tipo: Categorico
Moda: High school graduate
Valores faltantes: 0
Posibles valores: 10th grade, Some college but no degree, Doctorate degree(PhD EdD), Less than 1st
grade, 12th grade no diploma, Associates degree-academic program, Bachelors degree(BA AB BS),
High school graduate, Prof school degree (MD DDS DVM LLB JD), 9th grade, Associates degree-
20occup /vocational, 11th grade, Children, Masters degree(MA MS MEng MEd MSW MBA), 5th or
6th grade, 1st 2nd 3rd or 4th grade, 7th and 8th grade
Distribución
2.2.1.2.6 AHSCOL
AHSCOL
Indica si la persona se matriculó en algún tipo de educación en la última semana
Tipo: Categorico
Moda: Not in universe
Valores faltantes: 0
Posibles valores: College or university, High school, Not in universe
Distribución
212.2.1.2.7 AMARITL
AMARITL
Estado marital
Tipo: Categorico
Moda: Never married
Valores faltantes: 0
Posibles valores: Widowed, Married-A F spouse present, Never married, Divorced, Married-spouse
absent, Separated, Married-civilian spouse present
Distribución
2.2.1.2.8 AMJIND
AMJIND
Código principal de industria
Tipo: Categorico
Moda: Not in universe or children
Valores faltantes: 0
Posibles valores: Medical except hospital, Not in universe or children, Public administration, Forestry
and fisheries, Agriculture, Retail trade, Social services, Private household services, Construction,
Mining, Manufacturing-durable goods, Finance insurance and real estate, Armed Forces, Education,
Communications, Personal services except private HH, Hospital services, Transportation, Wholesale
trade, Business and repair services, Entertainment, Utilities and sanitary services, Manufacturing-
nondurable goods, Other professional services
22Distribución
2.2.1.2.9 AMJOCC
AMJOCC
Código principal de ocupación
Tipo: Categórico
Moda: Not in universe
Valores faltantes: 0
Posibles valores: Adm support including clerical, Private household services, Armed Forces,
Transportation and material moving, Machine operators assmblrs & inspctrs, Precision production
craft & repair, Protective services, Executive admin and managerial, Professional specialty, Sales,
Not in universe, Handlers equip cleaners etc , Other service, Technicians and related support,
Farming forestry and fishing
Distribución
2.2.1.2.10 ARACE
23ARACE
Raza de la persona censada
Tipo: Categórico
Moda: White
Valores faltantes: 0
Posibles valores: Black, Other, White, Asian or Pacific Islander, Amer Indian Aleut or Eskimo
Distribución
2.2.1.2.11 AREORGN
AREORGN
Origen hispánico de la persona
Tipo: Categórico
Moda: All other
Valores faltantes: 0
Posibles valores: Do not know, All other, Cuban, Mexican (Mexicano), Puerto Rican, Chicano,
Mexican-American, Central or South American, Other Spanish, NA
24Distribución
2.2.1.2.12 ASEX
ASEX
Indica el sexo de la persona
Tipo: Categórico
Moda: Female
Valores faltantes: 0
Posibles valores: Male, Female
Distribución
2.2.1.2.13 AUNMEM
25AUNMEM
Indica si la persona es miembro de algún sindicato.
Tipo: Categórico
Moda: Not in universe
Valores faltantes: 0
Posibles valores: Yes, Not in universe, No
Distribución
2.2.1.2.14 AUNTYPE
AUNTYPE
Razón de desempleo
Tipo: Categórico
Moda: Not in universe
Valores faltantes: 0
Posibles valores: Job loser - on layoff, Job leaver, Re-entrant, Not in universe, New entrant, Other
job loser
26Distribución
2.2.1.2.15 AWKSTAT
AWKSTAT
Indica el estado laboral de la persona, a tiempo completo o parcial.
Tipo: Categórico
Moda: Children or Armed Forces
Valores faltantes: 0
Posibles valores: Unemployed part- time, Full-time schedules, Not in labor force, Unemployed full-
time, Children or Armed Forces, PT for non-econ reasons usually FT, PT for econ reasons usually PT,
PT for econ reasons usually FT
Distribución
272.2.1.2.16 FILESTAT
FILESTAT
Estado de declaración de impuestos
Tipo: Categórico
Moda: Nonfiler
Valores faltantes: 0
Posibles valores: Joint both under 65, Head of household, Nonfiler, Joint both 65+, Joint one under
65 & one 65+, Single
Distribución
2.2.1.2.17 GRINREG
GRINREG
Región de la residencia anterior de la persona
Tipo: Categórico
Moda: Not in universe
Valores faltantes: 0
Posibles valores: Abroad, South, West, Not in universe, Midwest, Northeast
28Distribución
2.2.1.2.18 GRINST
GRINST
Estado de la residencia anterior de la persona
Tipo: Categórico
Moda: Not in universe
Valores faltantes: 708
Posibles valores: Kansas, North Dakota, Missouri, Maine, Pennsylvania, Abroad, Iowa, Ohio,
Louisiana, Arizona, West Virginia, Illinois, South Carolina, Arkansas, New Hampshire, Nevada,
California, Virginia, Colorado, Georgia, Minnesota, Alaska, New Mexico, Kentucky, Michigan,
Tennessee, District of Columbia, New Jersey, Oklahoma, Wyoming, Wisconsin, New York,
Alabama, Nebraska, Oregon, Connecticut, Indiana, Delaware, Not in universe, ?, Idaho, Montana,
Massachusetts, Maryland, Vermont, South Dakota, North Carolina, Florida, Texas, Mississippi,
Utah
29Distribución
2.2.1.2.19 HHDFMX
HHDFMX
Composición detallada del hogar y la familia
Tipo: Categórico
Moda: Householder
Valores faltantes: 0
Posibles valores: Other Rel <18 spouse of subfamily RP, Child under 18 of RP of unrel subfamily,
Secondary individual, Other Rel <18 never married RP of subfamily, Child 18+ ever marr RP of
subfamily, Child <18 never marr RP of subfamily, Nonfamily householder, Child <18 ever marr not
in subfamily, In group quarters, Other Rel <18 ever marr RP of subfamily, Grandchild 18+ never marr
RP of subfamily, Grandchild 18+ spouse of subfamily RP, Child 18+ spouse of subfamily RP,
Grandchild 18+ ever marr RP of subfamily, Spouse of RP of unrelated subfamily, RP of unrelated
subfamily, Other Rel 18+ never marr not in subfamily, Other Rel <18 never marr child of subfamily
RP, Grandchild 18+ never marr not in subfamily, Child 18+ never marr RP of subfamily, Child 18+
never marr Not in a subfamily, Other Rel 18+ never marr RP of subfamily, Grandchild 18+ ever marr
not in subfamily, Child 18+ ever marr Not in a subfamily, Child <18 never marr not in subfamily,
Other Rel 18+ ever marr not in subfamily, Other Rel <18 never marr not in subfamily, Other Rel 18+
spouse of subfamily RP, Child <18 spouse of subfamily RP, Grandchild <18 never marr child of
subfamily RP, Grandchild <18 never marr not in subfamily, Spouse of householder, Householder,
Other Rel 18+ ever marr RP of subfamily, Child <18 ever marr RP of subfamily, Grandchild <18
never marr RP of subfamily, Other Rel <18 ever marr not in subfamily, Grandchild <18 ever marr not
in subfamily
30Distribución
2.2.1.2.19 HHDREL
HHDREL
Resumen detallado de los miembros del hogar
Tipo: Categórico
Moda: Householder
Valores faltantes: 0
Posibles valores: Child under 18 ever married, Group Quarters- Secondary individual, Nonrelative of
householder, Other relative of householder, Child 18 or older, Child under 18 never married, Spouse
of householder, Householder
Distribución
2.2.1.2.20 MARSUPWT
MARSUPWT
31Este atributo no se debe tomar en cuenta para clasificadores de machine learning
2.2.1.2.21 MIGMTR1
MIGMTR1
Código de migración por cambio en MSA
Tipo: Categórico
Moda: ?
Valores faltantes: 0 (cabe recalcar que ` ?` es tomado como valor desconocido.
Posibles valores: MSA to MSA, NonMSA to MSA, Abroad to MSA, Abroad to nonMSA, MSA to
nonMSA, Not in universe, ?, Not identifiable, Nonmover, NonMSA to nonMSA
Distribución
2.2.1.2.22 MIGMTR3
MIGMTR3
Cambio de código de migración en el registro.
Tipo: Categórico
Moda: ?
Valores faltantes: 0 (cabe recalcar que ` ?` es tomado como valor desconocido.
Posibles valores: Abroad, Different county same state, Different region, Same county, Not in universe,
?, Nonmover, Different division same region, Different state same division
32Distribución
2.2.1.2.23 MIGMTR4
MIGMTR4
Código de migración. Traslado dentro de la región.
Tipo: Categórico
Moda: ?
Valores faltantes: 0 (cabe recalcar que ` ?` es tomado como valor desconocido.
Posibles valores: Different state in West, Abroad, Different state in South, Different state in Midwest,
Different county same state, Same county, Not in universe, ?, Different state in Northeast, Nonmover
Distribución
332.2.1.2.24 MIGSAME
MIGSAME
Indica si la persona vivía en el mismo lugar hace 1 año atrás.
Tipo: Categórico
Moda: Not in universe under 1 year old
Valores faltantes: 0
Posibles valores: Not in universe under 1 year old, Yes, No
Distribución
2.2.1.2.25 MIGSUN
MIGSUN
Indica si la persona vivía anteriormente en SunBelt
Tipo: Categórico
Moda: ?
Valores faltantes: 0 (cabe recalcar que ` ?` es tomado como valor desconocido.
Posibles valores: Yes, Not in universe, ?, No
34Distribución
2.2.1.2.26 PARENT
PARENT
Indica los padres presentes para menores de 18 años.
Tipo: Categórico
Moda: Not in universe
Valores faltantes: 0
Posibles valores: Neither parent present, Father only present, Not in universe, Both parents present,
Mother only present
Distribución
352.2.1.2.27 PEFNTVTY
PEFNTVTY
País de Nacimiento del padre
Tipo: Categórico
Moda: United-States
Valores faltantes: 0
Posibles valores: Dominican-Republic, Ireland, Cuba, Guatemala, Iran, Panama, El-Salvador,
Taiwan, Hong Kong, United-States, Japan, Nicaragua, Canada, Cambodia, Laos, Germany, South
Korea, Trinadad&Tobago, Peru, Ecuador, Yugoslavia, Vietnam, Philippines, Honduras, Jamaica,
England, India, Puerto-Rico, Holand-Netherlands, Italy, Scotland, Portugal, Outlying-U S (Guam
USVI etc), ?, Poland, Haiti, Thailand, China, Hungary, Greece, Columbia, Mexico, France
Distribución
2.2.1.2.27 PEMNTVTY
PEMNTVTY
País de Nacimiento de la madre
Tipo: Categórico
Moda: United-States
Valores faltantes: 0
Posibles valores: Dominican-Republic, Ireland, Cuba, Guatemala, Iran, Panama, El-Salvador,
Taiwan, Hong Kong, United-States, Japan, Nicaragua, Canada, Cambodia, Laos, Germany, South
Korea, Trinadad&Tobago, Peru, Ecuador, Yugoslavia, Vietnam, Philippines, Honduras, Jamaica,
England, India, Puerto-Rico, Holand-Netherlands, Italy, Scotland, Portugal, Outlying-U S (Guam
USVI etc), ?, Poland, Haiti, Thailand, China, Hungary, Greece, Columbia, Mexico, France
36Distribución
2.2.1.2.28 PENATVTY
PENATVTY
País de Nacimiento del encuestado
Tipo: Categórico
Moda: United-States
Valores faltantes: 0
Posibles valores: Dominican-Republic, Ireland, Cuba, Guatemala, Iran, Panama, El-Salvador,
Taiwan, Hong Kong, United-States, Japan, Nicaragua, Canada, Cambodia, Laos, Germany, South
Korea, Trinadad&Tobago, Peru, Ecuador, Yugoslavia, Vietnam, Philippines, Honduras, Jamaica,
England, India, Puerto-Rico, Holand-Netherlands, Italy, Scotland, Portugal, Outlying-U S (Guam
USVI etc), ?, Poland, Haiti, Thailand, China, Hungary, Greece, Columbia, Mexico, France
Distribución
372.2.1.2.29 PRCITSHP
PRCITSHP
Ciudadanía de la persona
Tipo: Categórico
Moda: Native- Born in the United States
Valores faltantes: 0
Posibles valores: Foreign born- Not a citizen of U S , Foreign born- U S citizen by naturalization,
Native- Born abroad of American Parent(s), Native- Born in Puerto Rico or U S Outlying, Native-
Born in the United States
Distribución
2.2.1.2.30 SEOTR
SEOTR
Indica si la persona es propietario de un negocio o si es independiente.
Tipo: Categórico
Moda: 0
Valores faltantes: 0
Posibles valores: 1, 0, 2
38Distribución
2.2.1.2.31 VETQVA
VETQVA
Indica si la persona completó el cuestionario de admisión para veteranos.
Tipo: Categórico
Moda: Not in universe
Valores faltantes: 0
Posibles valores: Yes, Not in universe, No
Distribución
392.2.1.2.32 VETYN
VETYN
Indica si la persona recibe beneficios de veterano.
Tipo: Categórico
Moda: 2
Valores faltantes: 0
Posibles valores: 1, 0, 2
Distribución
2.2.1.2.33 YEAR
YEAR
Año del censo
Tipo: Categórico
Moda: 94
Valores faltantes: 0
Posibles valores: 94, 95
40Distribución
2.2.2 Atributo de Clase.
Se identifica a “PTOTVAL” como el atributo de clase, con posibles valores de:
‘- 50000.’, ‘ 50000+.’ indicando si un individuo está por encima o debajo del umbral
de los $50.000.
El conjunto de datos está muy desequilibrado con un IR 1 : 15:11, por lo que existe una
precisión mayoritaria en la clase ‘- 50000.
Esto nos indica solo viendo el gráfico que nuestro modelo podría llegar a tener una tasa de
acierto del 93% debido a que los datos están tan sesgados, pero esto puede ser engañoso por la
41misma razón. Y para evaluar los algoritmos usados tendremos que basarnos mucho en la matriz
de confusión y la curva ROC.
2.2.3 Valores fuera de rango.
2.2.3.1 AAGE
En el atributo AAGE (edad), el conjunto muestra un rango de edad mínima entre los 0
y una máxima de 90 años.
Dado que los datos hacen relación al ingreso por fuerza laboral y que por ley en Estados
Unidos (el contexto), en general no está permitido trabajar a menores de 14 años, lo que
representan 44.354 registros, se puede considerar como valores fuera de rango.
Además, en dicha variable también se detectó una particularidad en las personas con
edad de 90 años. Son 725, y de estos solo 23 superan los 50,000. Se pudo validar que de esos
23, solo 11 trabajan todas las semanas lo cual puede generar ruido y sería prudente eliminar
este grupo.
2.2.4 Atributos con valores nulos o faltantes.
El conjunto de datos no cuenta con valores nulos, únicamente se identificaron valores
unknown o desconocidos “?” dentro de algunos atributos que no son muy relevantes para el
entrenamiento del modelo, pero en el caso que los utilicemos para iterar este valor si será
tomado en cuenta.
Atributo
Cantidad
de Porcentaje de unknown
unknown
GRINST
708
42
0,35%MIGMTR199.69649,96%
MIGMTR399.69649,96%
MIGMTR499.69649,96%
MIGSUN99.69649,96%
PEFNTVTY6.7133,36%
PEMNTVTY6.1193,07%
PENATVTY3.3931,70%
2.2.5 Outliers.
Los Outliers son valores atípicos que se alejan significativamente del patrón general del
resto de los datos. Una anomalía observable que no sigue una tendencia normal o esperable.
A continuación, un resumen de los análisis y la acción tomada para cada Outlier
identificado.
2.2.5.1. Outliers.
Acorde a los gráficos presentados para las variables numéricas, la detección de outliers
se dificulta debido a que la distribución está demasiado sesgada hacia los valores 0. Estos
valores son válidos acorde a cada campo por lo que no podrían llamarse outliers. Con todo
como esto puede afectar al model e introducir ruido o redundancia sin mejorar el desempeño.
En consecuencia, estos datos se considera candidatos a ser eliminado o transformado posterior
a revisar su relevancia o en iteraciones posteriores.
2.2.6 Atributos protegidos.
Un atributo protegido es una variable de entrada que contiene información sensible
sobre un individuo y que está legal o éticamente prohibido usar para tomar decisiones
discriminatorias. Este apartado cubre estos atributos, pero no entraremos en mitigación de
sesgos para nuestro modelo.
43Investigaciones anteriores consideran el sexo como un atributo protegido (Iosifidis y
Ntoutsi, 2019; Iosifidis y Ntoutsi, 2020; Ristanoskiet al., 2013).
El atributo sexo (sex) = {male, female}, se encuentra un poco desbalanceado en el data set:
El atributo raza (Race) = {White, Black, Other, Amer Indian Aleut or Eskimo, Asian
or Pacific Islander.} también podría emplearse como atributo protegido, ya que puede presentar
sesgos al momento de la clasificación.
El conjunto de entrenamiento está dominado por personas blancas; hay 167.365 (84,01
%) personas blancas, por lo que podríamos codificar la raza como un atributo binario para iterar
en nuestro modelo {white, non-white}
442.3 Análisis de correlación de los datos.
Antes de construir el modelo, realizaremos un análisis de correlación con un doble
objetivo: relevancia y redundancia. Para identificar atributos que no solo aporten valor
predictivo, sino que también evitemos la redundancia (multicolinealidad), para simplificar el
feature set y mejorar la eficiencia del entrenamiento.
Para este análisis, emplearemos métricas adaptadas al tipo de variable:
•
Variables Categóricas: La asociación entre features y la correlación con la variable
objetivo será evaluada utilizando el coeficiente Cramér's V (basado en Chi-Square).
•
Variables Numéricas: Usaremos el coeficiente de Spearman, dado que su
distribución no es normal. La relevancia con la variable objetivo binaria se
verificará mediante el coeficiente de Correlación Punto-Biserial.
2.3.1 Correlación con PTOTVAL
Aquí podemos visualizar la correlación completa de datos categóricos en relación a la
variable objetivo PTOTVAL. Esto nos va a dar una idea de que valores podríamos descartar
para el modelo:
45Ahora analizamos los atributos de más relevante a menos relevante, obteniendo las siguientes
gráficas de correlación y análisis:
2.3.2 Códigos de Industria.
46AMJIND y ADTIND tiene una muy alta correlación de 1 esto puede ser evidente ya
que los dos tratan respecto al código de industria (industry code) por lo que podemos pasar a
eliminar un de los dos. Nos quedaremos con ADTIND que tiene una correlación con
PTOTVAL de 0.293 un poco mayor a AMJIND.
Un caso similar sucede con ADTOCC y AMJOCC tienen una muy alta correlación de
1 esto puede ser evidente ya que los dos tratan respecto al código de ocupación (occupation
code) por lo que podemos pasar a eliminar un de los dos. Nos quedaremos con ADTOCC que
tiene una correlación con PTOTVAL de 0.438 mayor a AMJOCC.
2.3.3 Detalle de vivienda.
En esta gráfica podemos ver una muy alta correlación de 0.976 con los campos
HHDREL y HHDFMX esto se debe a que los dos representan valores de vivienda y estado
familiar (detailed household and family stat & detailed household summary in household).
Podemos proceder a quedarnos con HHDFMX debido a que tiene mayor correlación con la
variable objetivo 0.24
472.3.4 Lugares de residencia.
Dentro de los valores menos relevantes podemos ver una fuerte correlación entre
GRINREG y GRINST debido a que los dos tratan temas respecto a lugares previos de
residencia región y estado. Procedemos a quedarnos con GRINST en el caso que iteremos con
el modelo y decidamos quedarnos con este valor aunque es casi irrelevante para PTOTVAL.
2.3.5 Variables con baja relevancia y posibles opciones.
2.3.5.1 Residencia o cambio de residencia.
MIGMTR1, MIGMTR3, MIGMTR4, MIGSUN y MIGSAME tienen una
distribución y valores bastante parecida, para lo que procedemos a revisar su correlación:
48En el heatmap se observan dos grupos principales de alta correlación, donde los valores
oscilan por encima de 0.8 y hasta cerca de 1.0.
Grupo 1 (Muy Alta Asociación): MIGSAME, MIGSUN
Grupo 2 (Alta Asociación): MIGMTR1, MIGMTR3, MIGMTR4
Acorde a esto podríamos reducir redundancia dejando solo una variable del Grupo 1 y
una del Grupo 2.
La Cramér's V para todas estas variables es extremadamente baja, oscilando entre 0.028
MIGSAME y 0.039 MIGMTR1. Una V tan cercana a cero indica que estas variables poseen
nula o muy poca relevancia predictiva para clasificar PTOTVAL. En este caso, podemos
limpiar estos atributos omitiéndolos.
49Para iterar sobre el modelo, algo que podemos hacer si quisiéramos revisar si estos
afectan o no al mismo sería dejar MIGSUN del grupo 1 y MIGMTR1 que tienen un poco más
de correlación.
2.3.5.2 Variables relacionadas con el país de nacimiento.
PEFNTVTY, PEMNTVTY, PENATVTY es otro grupo de valores que tiene mucho
parecido entre sí, los tres indican países de nacimiento, al realizar el análisis de correlación de
estas tres variables podemos ver el siguiente resultado:
La correlación entre PEFNTVTY y PEMNTVTY es muy alto con un 0.82 por lo que
podemos hacer es dejar uno de ellos y PENATVTY si dejarlo por separado.
50Tienen muy baja correlación con la variable objetivo así que procedemos a omitirlas
para el modelo. Para iteraciones igualmente lo que podemos hacer si deseamos probar con estas
variables sería mantener PEFNTVTY y PENATVTY.
Algo interesante a tomar en cuenta para estas variables es que la mayoría de sus valores
se centran en “United-States” como vemos en su frecuencia:
El tener todas las opciones de países podría afectar la dimensionalidad si es que
decidiéramos utilizar OneHotEncoder, lo que podemos hacer para esto es tratarlo como binario
es decir “United-States” y “Foreign”. En el caso que quisiéramos iterar incluyendo estas
variables, esto podría ser una posibilidad que nos daría la distribución de frecuencia a
continuación:
51Para los campos restantes el más destacado es YEAR que tiene una correlación muy baja con
el objetivo (0.015) y podemos omitirla.
2.3.6 Correlación de las variables numéricas.
Se realizó la correlación de Spearman para los datos numéricos debido a su distribución
no normal. No tenemos ninguna correlación entre ellos como para considerar eliminar algún
dato por este motivo.
Para la correlación entre las variables numéricas y la variable objetivo se tiene el
siguiente resultado:
52Con lo cual AHRSPAY con una correlación muy baja puede ser eliminada del modelo.
2.4 Conclusiones del análisis de datos.
Basado en el análisis exploratorio de las secciones anteriores, se define el siguiente plan
de limpieza y preparación de datos:
2.4.1 Filtrado de Instancias
Se eliminarán los siguientes registros del conjunto de datos por considerarse ruido o
estar fuera del alcance del problema:
Registros fuera de la fuerza laboral (Edad < 14): Se eliminarán 44.354 registros donde
el atributo AAGE es menor de 14 años, ya que no representan a la población laboral activa.
Registros de 90 años: Se eliminarán los 725 registros donde AAGE es 90. Este grupo
se considera ruido, ya que el análisis mostró que solo una fracción mínima (11 de 725) ha
trabajado a tiempo completo.
2.4.2 Eliminación de Atributos
Los siguientes atributos serán eliminados para reducir la dimensionalidad, eliminar
redundancia y descartar información irrelevante:
Atributo de Peso: MARSUPWT ("instance weight") será ignorado, ya que no se lo
recomienda para clasificadores.
532.4.3 Atributos Numéricos Irrelevantes:
AHRSPAY: Se elimina debido a su correlación casi nula (0.025) con la variable
objetivo PTOTVAL.
2.4.4 Atributos Categóricos Redundantes:
AMJIND: Se elimina por tener una correlación de 1 con ADTIND (se conserva
ADTIND por su mayor correlación con el objetivo).
AMJOCC: Se elimina por tener una correlación de 1 con ADTOCC (se conserva
ADTOCC).
HHDREL: Se elimina por su alta correlación (0.976) con HHDFMX (se conserva
HHDFMX).
2.4.5 Atributos Categóricos Irrelevantes:
Variables de Migración: Se eliminan MIGMTR1, MIGMTR3, MIGMTR4, MIGSUN
y MIGSAME. Todas presentan una correlación V de Cramér extremadamente baja (entre 0.028
y 0.039) con el objetivo y están correlacionadas.
Variables de Nacimiento: Se eliminan PEFNTVTY, PEMNTVTY y PENATVTY.
Muestran una correlación casi nula con el objetivo (V de Cramér ≤ 0.022) y están
correlacionadas.
Variable YEAR: Tiene una correlación muy baja del 0.015 con el objetivo.
GRINREG y GRINST: Se eliminan por ser redundantes y tener una correlación muy
baja con el objetivo.
2.4.6 Transformaciones para posibles iteraciones posteriores:
Binarización de ARACE: El atributo de raza (ARACE), que está altamente
desbalanceado (84% 'White'), se podría transformará en una variable binaria: {'White', 'Non-
White'}.
En el caso de utilizar las variables PEFNTVTY, PEMNTVTY y PENATVTY se
transformarán en binarias {‘United-States’, ‘Foreign’}
54Para las variables numéricas, es muy posible que se deba simplificarlas de igual
manera debido a sus sesgos en la distribución. Con todo iniciaremos preservando la
integridad del conjunto original de variables para realizar un análisis completo del
comportamiento del modelo en iteraciones iniciales. Esto permitirá posteriormente evaluar
empíricamente el impacto de su inclusión o exclusión sobre las métricas de desempeño
3. Preparación de datos
3.1 Creación de conjuntos de entrenamiento y prueba.
Con respecto al conjunto de datos para entrenamiento y pruebas, estos fueron
disponibilizados como parte de la información original a través de los archivos census-
income.data y census-income.test, con proporciones aproximadas de 2/3 y 1/3 respectivamente.
El
origen
de
estos
datos
es
posibles
encontrarlos
en
la
dirección:
https://archive.ics.uci.edu/dataset/117/census+income+kdd
Además, dentro del conjunto de datos existe un tercer archivo llamado census-
income.names que incluye un resumen ejecutivo bastante completo acerca del contexto general
de la actividad, el ejercicio de predicción esperado, datos estadísticos generales del dataset, y
el detalle de los atributos tales como: nombre, tipo y posibles valores entre otros.
Este último archivo también especifica los procesos de limpieza y preparación. En este
sentido, indica que la limpieza incluyó:
-
El manejo de duplicados y de conflictos, tanto en el conjunto de datos principal
como el de pruebas.
-
Transformaciones de formato y estandarizaciones en pro de facilitar el
procesamiento.
3.2 Limpieza de datos.
Una vez realizado el análisis del conjunto de datos y sus atributos, la limpieza constará
en eliminar los campos duplicados, nulos y registros no válidos detectados.
Eliminación de campos nulos y duplicados:
/**
* Eliminar duplicados y na para confirmar instancias limpias
55*/
def filterNulls(df: DataFrame): DataFrame = {
println("\n\n ** Eliminando duplicados y nulos: \n Instancias Antes del filtro: \n"
+ df.count())
val filtered = df.na.drop().distinct()
println("Instancias despues del filtro: \n" + filtered.count())
filtered
}
Eliminación de registros fuera del rango de edad
/**
* Filtrar a los usuarios con menos de 14 años y los de 90 años
* Basándonos en el analisis de datos realizado
*/
def filterByAge(minAge: Int = 14, maxAge: Int = 90)(df: DataFrame): DataFrame =
df.filter(col("AAGE") >= minAge && col("AAGE") < maxAge
Finalmente se realiza la limpieza mediante composición de los dos métodos:
def
cleanUpRawDF(rawDF:
DataFrame):
DataFrame
=
rawDF.
transform(filterByAge(10,
90)).
transform(filterNulls)
Y se aplica la función de limpieza tanto para el conjunto de datos como para el de prueba:
println("Limpieza
val
de
cleanCensusDataDF
println("Limpieza
de
datos
=
de
entrenamiento:")
cleanUpRawDF(rawCensusDataDF)
datos
val cleanTestCensusDataDF = cleanUpRawDF(rawCensusTestDF)
56
de
prueba:")La tasa de no clasificados: (NTAIE+NTOE)/(tamaño conjunto de prueba)
Esta tasa depende mucho del filtro de edad que hemos colocado, y puede ser muy
restrictivo para el conjunto de pruebas. Al momento se encuentra en un valor moderado, pero
esto justamente muestra el sesgo que tiene el conjunto hacia el valor 0 en la edad. Podemos ir
probando con el filtro de edad para obtener mejores resultados. El resultado mostrado se lo da
con un filtro que elimina las instancias menores a de 10 años y de 90 años.
3.3 Selección de atributos.
Para la selección de atributos hemos realizado la estrategia manual, pero realizando el
análisis de cada atributo a través de la comprensión de problema y adicionalmente aplicando
los método para verificar distribuciones, correlaciones y relevancia. Cabe recalcar que hay
espacio para una selección de datos semi-automática que se la podría hacer mediante
UnivariateFeatureSelector de ML que es la nueva versión tras deprecar ChiSqSelector. Este
método es univariante y permitiría confirmar decisiones o eliminar atributos adicionales de ser
el caso.
A través del análisis realizado que nos permitió comprender el problema, sus atributos
y correlaciones entre ellos se procede a eliminar los atributos redundantes o poco relevantes
primero creando colecciones de cada tipo de atributo a descartar debido a sus razones:
// Estos son los atributos que se han detectado mediante métodos manuales usando
// técnicas de detección de correlación chiSquare y Cramer's V
57val avoidedAttr = Seq("MARSUPWT")
val irrelevantAttr = Seq(
"AHRSPAY", "MIGMTR1", "MIGMTR3", "MIGMTR4", "MIGSUN", "MIGSAME",
"PEFNTVTY", "PEMNTVTY", "PENATVTY",
"YEAR",
"GRINST", "GRINREG",
)
val correlatedAttr = Seq(
"AMJIND", "AMJOCC", "HHDREL"
)
val excludedColumns = avoidedAttr ++ irrelevantAttr ++ correlatedAttr
Y creando una función que nos permitirá aplicarla tanto al conjunto de entrenamiento
como de prueba:
/**
* Descartar los atributos que no van a ser utilizados para la clasificacion
* Y seleccionar solo los que van a utilizar
*/
def attributeSelection(excludedCols: Seq[String])(df: DataFrame): DataFrame =
df.select(df.columns.diff(excludedCols).map(col): _*)
println("Seleccion de datos en el conjunto de entrenamiento:")
val selectedCensusDataDF = attributeSelection(excludedColumns)(cleanCensusDataDF)
println("Seleccion de datos en el conjunto de datos de prueba:")
val selectedTestCensusDataDF =
attributeSelection(excludedColumns)(cleanTestCensusDataDF)
3.4 Transformación de datos.
En esta primera iteración se aplicará StringIndexer a los atributos categóricos para
convertirlos en valores numéricos aptos para el modelado. Se ha decidido no utilizar aún
58OneHotEncoder, ya que el conjunto cuenta con 26 atributos y esta técnica incrementaría
considerablemente la dimensionalidad, afectando la eficiencia en esta fase exploratoria.
Dado que los modelos basados en árboles de decisión pueden manejar variables
indexadas directamente, esta codificación resulta suficiente por ahora. En etapas posteriores, si
se implementan modelos lineales como Regresión Logística, se incorporará OneHotEncoder
para evitar interpretaciones ordinales y mejorar la representación de las categorías.
Este enfoque permite mantener un equilibrio entre simplicidad y rendimiento mientras
se evalúa el comportamiento inicial del modelo.
Empezamos el proceso indexando los atributos categóricos
/**
* Separamos los categóricos de los numericos
*/
val numericCols = Array("AAGE","CAPGAIN","CAPLOSS","DIVVAL", "NOEMP","WKSWORK")
val categoricalCols = censusDataDF.columns.filterNot(numericCols.contains).filter(_ !=
"PTOTVAL")
/**
* Indexamos únicamente los categóricos
*/
val stringIndexerCategoricalCols = new StringIndexer()
.setInputCols(categoricalCols)
.setOutputCols(categoricalCols.map(_ + "-idx"))
.setStringOrderType("alphabetDesc"
val dfIndexed = stringIndexerCategoricalCols.fit(censusDataDF).transform(censusDataDF)
Unimos tanto categóricos como numéricos para ensamblar el vector de features:
/**
*Unimoslosatributos
*SinincluirPTOTVAL
numéricos
que
59
y
es
categoricos
el
label*/
val
featureCols
=
numericCols
++
categoricalCols.map(_
+
"-idx")
Creamos el vector de features y lo unimos a la clase:
/**
* Crear el vector de features
*/
val featuresVector = new VectorAssembler()
.setInputCols(featureCols)
.setOutputCol("features")
// Creamos el DataFrame con columnas features y clase
val censusFeaturesClaseDF = featuresVector.transform(dfIndexed).select("features",
"PTOTVAL")
Finalmente creamos el índice de la clase, renombramos a label la clase y realizamos la
transformación.
/** Transformamos la etiqueta de clase PTOTVAL a enteros
* y renombramos la columna "PTOTVAL" a "label"
* también con StringIndexer
*/
// creamos el StringIndexer para la clase
val indiceClase= new
StringIndexer().setInputCol("PTOTVAL").setOutputCol("label").setStringOrderType("alpha
betDesc")
// Creamos el DataFrame con columnas features y label
val censusFeaturesLabelDF =
60indiceClase.fit(censusFeaturesClaseDF).transform(censusFeaturesClaseDF).drop("PTOTVAL"
)
Con esto obtenemos el vector con índices listo para poder utilizarlo para el
entrenamiento del modelo.
4. Conclusiones
En esta primera fase del proyecto se abordó un problema de clasificación binaria
utilizando el conjunto de datos Census Income (KDD), con el objetivo de predecir si una
persona presenta ingresos anuales superiores a 50.000 dólares.
El trabajo permitió comprender en profundidad la estructura, naturaleza y complejidad
del dataset, recopilado por la Oficina del Censo de los Estados Unidos a partir de las Current
Population Surveys de 1994 y 1995.
A través del análisis exploratorio se identificaron el origen, propósito y composición
del conjunto, detallando sus más de 199.000 instancias y 40 atributos de distinta naturaleza
(numéricos, categóricos y discretos). Se evaluaron distribuciones, correlaciones y posibles
inconsistencias, lo que facilitó la detección de valores faltantes, ruido, outliers y atributos de
baja relevancia predictiva.
61En la fase de preparación, se implementaron estrategias de limpieza, selección y
transformación de datos orientadas a mejorar la calidad del conjunto y a garantizar su idoneidad
para el entrenamiento de modelos supervisados.
En conjunto, esta etapa exploratoria ha proporcionado una base sólida y confiable para
las fases posteriores del proyecto. La comprensión obtenida sobre la estructura y calidad de los
datos será esencial para construir modelos más precisos, interpretables y generalizables en las
siguientes iteraciones.
5. Participación
Rocha, Nataly
•Horas: 22 Horas
•Actividades: Creación de los scripts de Scala para el análisis, exportación de archivos
csv con los resultados obtenidos para posterior uso en R, limpieza, selección de datos y
transformación. Script en R para la creación de gráficos y análisis del conjunto de datos.
Investigación del problema y análisis estadístico completo respecto a la distribución,
dispersión, outliers y correlación de datos para el proceso de selección de atributos
adecuados para el modelo. Redacción del documento a través de los datos obtenidos
con los scripts y el análisis.
Avendaño, Romell E.
•Horas: 16 Horas.
•Actividades: Diseño preliminar de la memoria (estructura y forma) y corredactor de
esta (fondo). Primera exploración del conjunto de datos en duro, lo que permitió
62elaborar hipótesis iniciales. Foco en la exploración de los datos (puntos 2.1 y 2.2).
Análisis del conjunto de los datos, especialmente en descripción de los atributos,
atributo de clase, valores fuera de rango o nulos y outliers. Testeo y validación sobre
scripts obtenidos tanto en Spark Shell como en R. Recolección y validación de material
bibliográfico sobre aplicabilidad y propósitos en la vida real para modelos predictivos
de esta naturaleza. Revisor general del documento.
Iribarren, Oscar.
•Horas: 16 Horas
•Actividades: Corredactor de la memoria, Introducción, resumen ejecutivo del conjunto
de datos, descripción del problema, interés del problema, investigación de aplicaciones
del problema, complejidades del problema (ruido de datos, valores faltantes e
inconsistencia de atributos), preparación de datos y pruebas de archivos .scala en Spark-
shell.
6. Referencias Bibliográficas
● Ristanoski, G., Liu, W., & Bailey, J. (2013). Discrimination aware classification for
imbalanced datasets. Proceedings of the 22nd ACM International Conference on
Information
and
Knowledge
Management
(CIKM),
1529-1532.
https://doi.org/10.1145/2505515.2507836
● Ntoutsi, E., Fafalios, P., Gadiraju, U., Iosifidis, V., Nejdl, W., Vidal, M. E., Ruggieri,
S., Turini, F., Papadopoulos, S., Krasanakis, E., Kompatsiaris, I., Kinder-Kurlanda, K.,
Wagner, C., Karimi, F., Fernández, M., Alani, H., Berendt, B., Kruegel, T., Heinze, C.,
… Staab, S. (2020). Bias in data-driven artificial intelligence systems—An introductory
survey. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery,
10(3), Article e1356. https://doi.org/10.1002/widm.1356
● Iosifidis, V., & Ntoutsi, E. (2019). AdaFair: Cumulative Fairness Adaptive Boosting.
Proceedings of the 28th ACM International Conference on Information and Knowledge
Management (CIKM) (pp. 781–790). ACM. https://doi.org/10.1145/3357384.3357974
63● Open Data Watch. (2021, 23 de octubre). Census Data Drives Decision Making. Open
Data
Watch.
https://opendatawatch.com/whats-being-said-resource/census-data-
drives-decision-making/
● United Nations Development Programme. (s. f.). Artificial intelligence for sustainable
development. https://www.undp.org/digital/ai
● ScienceDirect.
(s.
f.).
Population
census.
Social
Sciences
Topics.
https://www.sciencedirect.com/topics/social-sciences/population-census
● Becker, B., & Kohavi, R. (1996). Adult [Data set]. UCI Machine Learning Repository.
https://archive.ics.uci.edu/dataset/2/adult
● Apache Software Foundation. (2024). pyspark.ml.feature.OneHotEncoder — PySpark
3.5.0
documentation.
Apache
Spark.
https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.OneH
otEncoder.html
● Le Quy, T., Roy, A., Iosifidis, V., Zhang, W., & Ntoutsi, E. (2022). A survey on datasets
for fairness-aware machine learning. WIREs Data Mining and Knowledge Discovery,
12(3), e1452. https://doi.org/10.1002/widm.1452
64
